{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "P_HYuHz0Bl5S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 14:11:47.980498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import base64\n",
    "import copy\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "random.seed(a=1234567)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DD-gKEVKl_HY"
   },
   "source": [
    "Preprocessing CAN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User inputs\n",
    "no_of_2_grams = 256 #Number of 2-gram TF-IDF features\n",
    "no_of_3_grams = 0 #Number of 3-gram TF-IDF features\n",
    "input_type = \"Char\" #Byte, Char or All\n",
    "take_id = True #Take CAN ID as a feature\n",
    "\n",
    "# Set the input CSV file \n",
    "# Make sure it is in correct format with following columns in the order - ID, Data, Label\n",
    "input_csv_file = 'dataset_csv/Attack_Dataset_Driving_no_duplicates.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output csv file path to save csv without id column\n",
    "dataset_file_no_id = 'dataset_csv/temp/Attacks_D_Sliding_Window_no_id.csv'\n",
    "\n",
    "# Open the input and output files\n",
    "with open(input_csv_file, 'r') as file_in, open(dataset_file_no_id, 'w', newline='') as file_out:\n",
    "    # Create CSV reader and writer objects\n",
    "    reader = csv.reader(file_in)\n",
    "    writer = csv.writer(file_out)\n",
    "    \n",
    "    # Iterate over the rows in the input file\n",
    "    for row in reader:\n",
    "        # Write all columns except the first one to the output file\n",
    "        writer.writerow(row[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output csv file path to save csv with only id column\n",
    "if take_id:\n",
    "    # Specify the input and output file paths\n",
    "    dataset_file_all_id = 'dataset_csv/temp/Attacks_D_Sliding_Window_all_id.csv'\n",
    "\n",
    "    # Open the input and output files\n",
    "    with open(input_csv_file, 'r') as file_in, open(dataset_file_all_id, 'w', newline='') as file_out:\n",
    "        # Create CSV reader and writer objects\n",
    "        reader = csv.reader(file_in)\n",
    "        writer = csv.writer(file_out)\n",
    "\n",
    "        # Iterate over the rows in the input file\n",
    "        for row in reader:\n",
    "            # Write all columns except the first one to the output file\n",
    "            writer.writerow(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C5 00 FC 00 C7 00 8D 0A Spoofing\n",
      "00 00 08 06 00 DE 7A C0 Spoofing\n",
      "00 00 08 06 00 DE 7A C0\n"
     ]
    }
   ],
   "source": [
    "# Convert the CSV file to Text file and Save another csv with only Labels\n",
    "Labels_FileName = 'dataset_csv/temp/Sliding_Window_Labels.csv'\n",
    "Binaries_FileName = 'dataset_csv/temp/Vectors.txt'\n",
    "\n",
    "with open(dataset_file_no_id, 'r') as infile:\n",
    "  Sliding_Window_List = []\n",
    "  for line in infile:\n",
    "    Sliding_Window_List.append(line.strip())\n",
    "\n",
    "Sliding_Window_List = [Sliding_Window_List[ii].replace(\",\", \" \") for ii in range(0, len(Sliding_Window_List))]\n",
    "print(Sliding_Window_List[0])\n",
    "print(Sliding_Window_List[1])\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(Labels_FileName, 'w', newline='') as file:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.writer(file)\n",
    "\n",
    "    # Write each row with the same value\n",
    "    for lst in Sliding_Window_List:\n",
    "        csv_writer.writerow([lst.rsplit(' ', 1)[1]])\n",
    "\n",
    "#We need to change this for other labels\n",
    "Sliding_Window_Vector = [lst.rsplit(' ', 1)[0] for lst in Sliding_Window_List]\n",
    "print(Sliding_Window_Vector[1])\n",
    "\n",
    "#Write all binaries without labels in file\n",
    "with open(Binaries_FileName, 'w') as f:\n",
    "    for row in Sliding_Window_Vector:\n",
    "        f.write(''.join(map(str, row)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709962\n"
     ]
    }
   ],
   "source": [
    "if take_id:\n",
    "    min_value = 0\n",
    "    max_value = 2048\n",
    "    with open(dataset_file_all_id, 'r') as infile:\n",
    "        Id_List = []\n",
    "        for line in infile:\n",
    "            Id_List.append(line.strip())\n",
    "\n",
    "    Id_List = [Id_List[ii].replace(\",\", \"\") for ii in range(0, len(Id_List))]\n",
    "    Id_List = [int(Id_List[ii],16) for ii in range(0, len(Id_List))]\n",
    "    Id_List = [(x - min_value) / (max_value - min_value) for x in Id_List]    \n",
    "    print(len(Id_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Labels: dict_keys(['Spoofing', 'Normal', 'Fuzzing'])\n",
      "Label Info: dict_values([164410, 500078, 45474])\n",
      "Minimum number of data points in a class: 45474\n",
      "defaultdict(<class 'list'>, {0: [0], 1: [1], 2: [2]})\n",
      "Label to Integer Info: {'Spoofing': 0, 'Normal': 1, 'Fuzzing': 2}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "label_counter = Counter()\n",
    "num_duplicates = 0\n",
    "label_list = []\n",
    "\n",
    "with open(Binaries_FileName,\"r\") as raw_binaries_file, open(Labels_FileName,\"r\") as binaries_label_file:\n",
    "    for _, label_value_tmp in zip(raw_binaries_file, binaries_label_file):\n",
    "        label_value = label_value_tmp.rstrip('\\n')\n",
    "        label_counter[label_value] += 1\n",
    "        label_list.append(label_value)\n",
    "\n",
    "# We're using a Counter object, so we can simply print its items\n",
    "print('Distinct Labels:', label_counter.keys())\n",
    "print('Label Info:', label_counter.values())\n",
    "\n",
    "min_len = min(label_counter.values()) \n",
    "print('Minimum number of data points in a class:', min_len)\n",
    "\n",
    "# Convert string labels to integers\n",
    "labels_to_integers = {label: i for i, label in enumerate(label_counter.keys())} #labels_to_integers\n",
    "label_list_numeric = [labels_to_integers[label] for label in label_list]\n",
    "class_data_info = defaultdict(list)\n",
    "\n",
    "#Collecting indices belong to each class \n",
    "for i, label in enumerate(label_counter.keys()):\n",
    "    class_data_info[labels_to_integers[label]].append(i)\n",
    "\n",
    "print(class_data_info)\n",
    "\n",
    "class_data_info = []\n",
    "for ii in range(0, len(label_counter.keys())):\n",
    "    class_data_info.append([])\n",
    "\n",
    "#Collecting indices belong to each class\n",
    "for ii in range(0, len(label_list)):\n",
    "    class_data_info[label_list_numeric[ii]].append(ii)\n",
    "\n",
    "print('Label to Integer Info:', labels_to_integers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data per class: 36379\n",
      "Number of testing data per class: 9095\n"
     ]
    }
   ],
   "source": [
    "#Train Test Split\n",
    "train_dps_per_class = int(min_len*0.8)\n",
    "test_dps_per_class = min_len - train_dps_per_class\n",
    "\n",
    "print('Number of training data per class:', train_dps_per_class)\n",
    "print('Number of testing data per class:', test_dps_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting same number of samples for each class of architecture -> (Data Balancing in each class)\n",
    "picked_data_indices_train = [[] for _ in range(len(labels_to_integers))]\n",
    "picked_data_indices_test = [[] for _ in range(len(labels_to_integers))]\n",
    "\n",
    "for ii in range(len(labels_to_integers)):\n",
    "    train_dps = min(train_dps_per_class, len(class_data_info[ii]))\n",
    "    test_dps = min(test_dps_per_class, len(class_data_info[ii]) - train_dps)\n",
    "\n",
    "    if train_dps > 0:\n",
    "        picked_data_indices_train[ii] += random.sample(class_data_info[ii], train_dps)\n",
    "        class_data_info[ii] = list(set(class_data_info[ii]).difference(set(picked_data_indices_train[ii])))\n",
    "    \n",
    "    if test_dps > 0:\n",
    "        picked_data_indices_test[ii] += random.sample(class_data_info[ii], test_dps)\n",
    "        class_data_info[ii] = list(set(class_data_info[ii]).difference(set(picked_data_indices_test[ii])))\n",
    "\n",
    "Binaries_DataSets_train = []\n",
    "Binaries_DataSets_test = []\n",
    "Binaries_LabelSets_train = []\n",
    "Binaries_LabelSets_test = []\n",
    "Binaries_IdSets_train = []\n",
    "Binaries_IdSets_test = []\n",
    "\n",
    "for ii in range(0, len(labels_to_integers)):\n",
    "    Binaries_DataSets_train += [Sliding_Window_Vector[index] for index in picked_data_indices_train[ii]]\n",
    "    Binaries_LabelSets_train += [label_list[index] for index in picked_data_indices_train[ii]]\n",
    "    Binaries_DataSets_test += [Sliding_Window_Vector[index] for index in picked_data_indices_test[ii]]\n",
    "    Binaries_LabelSets_test += [label_list[index] for index in picked_data_indices_test[ii]]\n",
    "    \n",
    "    if take_id:\n",
    "        Binaries_IdSets_train += [Id_List[index] for index in picked_data_indices_train[ii]]\n",
    "        Binaries_IdSets_test += [Id_List[index] for index in picked_data_indices_test[ii]]\n",
    "\n",
    "with open(\"DistinctLabels.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(labels_to_integers, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N79l7a1JR8Us"
   },
   "source": [
    "### (2) Byte-level N-Gram TF-IDF Features\n",
    "Extract (1,2,3)-Gram TF-IDF features from binaries in Hex format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to concatenate two pandas dataframes with unique column names\n",
    "def concat_dfs(df1, df2):    \n",
    "    shift_value = df1.shape[1]\n",
    "    column_reindex = []\n",
    "    \n",
    "    for ii in range(0,df2.shape[1]):\n",
    "        column_reindex.append(str(ii+shift_value))\n",
    "\n",
    "    dictOfColumn_reindex = { ii : column_reindex[ii] for ii in range(0, len(column_reindex)) }\n",
    "    df2 = df2.rename(dictOfColumn_reindex, axis='columns')\n",
    "    df = pd.concat([df1, df2], axis = 1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate N-gram Byte level features for N = 1,2,3 based on user input and concatenate into one dataframe\n",
    "if input_type == \"Byte\":\n",
    "    vectorizer_12 = TfidfVectorizer(ngram_range = (1,1), lowercase = False)\n",
    "    #fit TF-IDF model using training data and transform training data according to the fitted model\n",
    "    X_train_12 = vectorizer_12.fit_transform(Binaries_DataSets_train)\n",
    "    df_train_Byte_TFIDF_feat_12 = pd.DataFrame(X_train_12.toarray())\n",
    "    df_train_Byte_TFIDF_feat_12['label'] = Binaries_LabelSets_train\n",
    "\n",
    "    ## Transform test data using the fitted model\n",
    "    X_test_12 = vectorizer_12.transform(Binaries_DataSets_test)\n",
    "    df_test_Byte_TFIDF_feat_12 = pd.DataFrame(X_test_12.toarray())\n",
    "    df_test_Byte_TFIDF_feat_12['label'] = Binaries_LabelSets_test\n",
    "    if take_id:\n",
    "        df_train_Byte_TFIDF_feat_12['id'] = Binaries_IdSets_train\n",
    "        df_test_Byte_TFIDF_feat_12['id'] = Binaries_IdSets_test\n",
    "\n",
    "    #For no concatenation case\n",
    "    if no_of_2_grams == 0 and no_of_3_grams == 0:\n",
    "        df_train_Byte_TFIDF_feat = df_train_Byte_TFIDF_feat_12\n",
    "        df_test_Byte_TFIDF_feat = df_test_Byte_TFIDF_feat_12\n",
    "\n",
    "    if no_of_2_grams > 0:\n",
    "        vectorizer_22 = TfidfVectorizer(ngram_range = (2,2), max_features = no_of_2_grams, lowercase = False)\n",
    "        #fit TF-IDF model using training data and transform training data according to the fitted model\n",
    "        X_train_22 = vectorizer_22.fit_transform(Binaries_DataSets_train)\n",
    "        df_train_Byte_TFIDF_feat_22 = pd.DataFrame(X_train_22.toarray())\n",
    "\n",
    "        #transform test data using the fitted model\n",
    "        X_test_22 = vectorizer_22.transform(Binaries_DataSets_test)\n",
    "        df_test_Byte_TFIDF_feat_22 = pd.DataFrame(X_test_22.toarray())\n",
    "\n",
    "    if no_of_3_grams > 0:\n",
    "        vectorizer_3 = TfidfVectorizer(ngram_range = (3,3),max_features = no_of_3_grams,lowercase = False)\n",
    "        #fit TF-IDF model using training data and transform training data according to the fitted model\n",
    "        X_train_3 = vectorizer_3.fit_transform(Binaries_DataSets_train)\n",
    "        df_train_Byte_TFIDF_feat_3 = pd.DataFrame(X_train_3.toarray())\n",
    "\n",
    "        # #transform test data using the fitted model\n",
    "        X_test_3 = vectorizer_3.transform(Binaries_DataSets_test)\n",
    "        df_test_Byte_TFIDF_feat_3 = pd.DataFrame(X_test_3.toarray())\n",
    "\n",
    "    # For Concatenation case\n",
    "    if no_of_2_grams > 0:\n",
    "        df_train_Byte_TFIDF_feat = concat_dfs(df_train_Byte_TFIDF_feat_12, df_train_Byte_TFIDF_feat_22)\n",
    "        df_test_Byte_TFIDF_feat = concat_dfs(df_test_Byte_TFIDF_feat_12, df_test_Byte_TFIDF_feat_22)\n",
    "\n",
    "    if no_of_2_grams > 0 and no_of_3_grams > 0:\n",
    "        df_train_Byte_TFIDF_feat = concat_dfs(df_train_Byte_TFIDF_feat, df_train_Byte_TFIDF_feat_3)\n",
    "        df_test_Byte_TFIDF_feat = concat_dfs(df_test_Byte_TFIDF_feat, df_test_Byte_TFIDF_feat_3)\n",
    "\n",
    "    if no_of_3_grams > 0 and no_of_2_grams == 0:\n",
    "        df_train_Byte_TFIDF_feat = concat_dfs(df_train_Byte_TFIDF_feat_12, df_train_Byte_TFIDF_feat_3)\n",
    "        df_test_Byte_TFIDF_feat = concat_dfs(df_test_Byte_TFIDF_feat_12, df_test_Byte_TFIDF_feat_3)\n",
    "\n",
    "    df_train_Byte_TFIDF_feat = df_train_Byte_TFIDF_feat.sample(frac=1)\n",
    "    df_test_Byte_TFIDF_feat = df_test_Byte_TFIDF_feat.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdaIj6nfXb8a"
   },
   "source": [
    "Data processing for Character level TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TUUnh1g4Xao1"
   },
   "outputs": [],
   "source": [
    "#Remove all spaces in data field for calculating character level features\n",
    "Binaries_DataSets_train_B16 = [Binaries_DataSets_train[ii].replace(\" \", \"\") for ii in range(0, len(Binaries_DataSets_train))]\n",
    "Binaries_DataSets_test_B16 = [Binaries_DataSets_test[ii].replace(\" \", \"\") for ii in range(0, len(Binaries_DataSets_test))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCbaNu-pJ5TR"
   },
   "source": [
    "Character level (1,2,3)-gram TF-IDF (Change list parameters after discussion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "03nXjhF_U6yk"
   },
   "outputs": [],
   "source": [
    "#Calculate N-gram Character level features for N = 1,2,3 based on user input and concatenate into one dataframe\n",
    "if input_type == \"Char\":\n",
    "    vectorizer_11_B16 = TfidfVectorizer(ngram_range = (1,1), lowercase = False, analyzer = 'char')\n",
    "    #fit TF-IDF model using training data and transform training data according to the fitted model\n",
    "    X_train_11_B16 = vectorizer_11_B16.fit_transform(Binaries_DataSets_train_B16)\n",
    "    df_train_CharB16_TFIDF_feat_11 = pd.DataFrame(X_train_11_B16.toarray())\n",
    "    df_train_CharB16_TFIDF_feat_11['label'] = Binaries_LabelSets_train\n",
    "    \n",
    "    #transform test data using the fitted model\n",
    "    X_test_11_B16 = vectorizer_11_B16.transform(Binaries_DataSets_test_B16)\n",
    "    df_test_CharB16_TFIDF_feat_11 = pd.DataFrame(X_test_11_B16.toarray())\n",
    "    df_test_CharB16_TFIDF_feat_11['label'] = Binaries_LabelSets_test\n",
    "    \n",
    "    if take_id:\n",
    "        df_train_CharB16_TFIDF_feat_11['id'] = Binaries_IdSets_train\n",
    "        df_test_CharB16_TFIDF_feat_11['id'] = Binaries_IdSets_test\n",
    "    ##For no concat\n",
    "    if no_of_2_grams == 0 and no_of_3_grams == 0:\n",
    "        df_train_Char_TFIDF_feat = df_train_CharB16_TFIDF_feat_11\n",
    "        df_test_Char_TFIDF_feat = df_test_CharB16_TFIDF_feat_11\n",
    "\n",
    "    if no_of_2_grams > 0:\n",
    "        vectorizer_22_B16 = TfidfVectorizer(ngram_range = (2,2), max_features = no_of_2_grams, lowercase = False, analyzer = 'char')\n",
    "        #fit TF-IDF model using training data and transform training data according to the fitted model\n",
    "        X_train_22_B16 = vectorizer_22_B16.fit_transform(Binaries_DataSets_train_B16)\n",
    "        df_train_CharB16_TFIDF_feat_22 = pd.DataFrame(X_train_22_B16.toarray())\n",
    "\n",
    "        #transform test data using the fitted model\n",
    "        X_test_22_B16 = vectorizer_22_B16.transform(Binaries_DataSets_test_B16)\n",
    "        df_test_CharB16_TFIDF_feat_22 = pd.DataFrame(X_test_22_B16.toarray())\n",
    "\n",
    "    if no_of_3_grams > 0:\n",
    "        vectorizer_33_B16 = TfidfVectorizer(ngram_range = (3,3), max_features = no_of_3_grams, lowercase = False, analyzer = 'char')\n",
    "        #fit TF-IDF model using training data and transform training data according to the fitted model\n",
    "        X_train_33_B16 = vectorizer_33_B16.fit_transform(Binaries_DataSets_train_B16)\n",
    "        df_train_CharB16_TFIDF_feat_33 = pd.DataFrame(X_train_33_B16.toarray())\n",
    "\n",
    "        #transform test data using the fitted model\n",
    "        X_test_33_B16 = vectorizer_33_B16.transform(Binaries_DataSets_test_B16)\n",
    "        df_test_CharB16_TFIDF_feat_33 = pd.DataFrame(X_test_33_B16.toarray())\n",
    "    \n",
    "    # Concatenations \n",
    "    if no_of_2_grams > 0:\n",
    "        df_train_Char_TFIDF_feat = concat_dfs(df_train_CharB16_TFIDF_feat_11, df_train_CharB16_TFIDF_feat_22)\n",
    "        df_test_Char_TFIDF_feat = concat_dfs(df_test_CharB16_TFIDF_feat_11, df_test_CharB16_TFIDF_feat_22)\n",
    "    \n",
    "    if no_of_2_grams > 0 and no_of_3_grams > 0:\n",
    "        df_train_Char_TFIDF_feat = concat_dfs(df_train_Char_TFIDF_feat, df_train_CharB16_TFIDF_feat_33)\n",
    "        df_test_Char_TFIDF_feat = concat_dfs(df_test_Char_TFIDF_feat, df_test_CharB16_TFIDF_feat_33)\n",
    "\n",
    "    if no_of_3_grams > 0 and no_of_2_grams == 0:\n",
    "        df_train_Char_TFIDF_feat = concat_dfs(df_train_CharB16_TFIDF_feat_11, df_train_CharB16_TFIDF_feat_33)\n",
    "        df_test_Char_TFIDF_feat = concat_dfs(df_test_CharB16_TFIDF_feat_11, df_test_CharB16_TFIDF_feat_33)\n",
    "\n",
    "    df_train_Char_TFIDF_feat = df_train_Char_TFIDF_feat.sample(frac=1)\n",
    "    df_test_Char_TFIDF_feat = df_test_Char_TFIDF_feat.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all pandas data frames to numpy arrays\n",
    "if input_type==\"Char\":\n",
    "    df_train_Byte_TFIDF_feat_label_convert = df_train_Char_TFIDF_feat.replace({'label' : labels_to_integers})\n",
    "    df_train_Byte_TFIDF_feat_no_label = df_train_Byte_TFIDF_feat_label_convert.drop('label', axis=1)\n",
    "    inputs = df_train_Byte_TFIDF_feat_no_label.to_numpy()\n",
    "    outputs_string = df_train_Char_TFIDF_feat['label'].to_numpy()\n",
    "\n",
    "    df_test_Byte_TFIDF_feat_label_convert = df_test_Char_TFIDF_feat.replace({'label' : labels_to_integers})\n",
    "    df_test_Byte_TFIDF_feat_no_label = df_test_Byte_TFIDF_feat_label_convert.drop('label', axis=1)\n",
    "    inputs_test = df_test_Byte_TFIDF_feat_no_label.to_numpy()\n",
    "    outputs_string_test = df_test_Char_TFIDF_feat['label'].to_numpy()\n",
    "else:\n",
    "    df_train_Byte_TFIDF_feat_label_convert = df_train_Byte_TFIDF_feat.replace({'label' : labels_to_integers})\n",
    "    df_train_Byte_TFIDF_feat_no_label = df_train_Byte_TFIDF_feat_label_convert.drop('label', axis=1)\n",
    "    inputs = df_train_Byte_TFIDF_feat_no_label.to_numpy()\n",
    "    outputs_string = df_train_Byte_TFIDF_feat['label'].to_numpy()\n",
    "\n",
    "    df_test_Byte_TFIDF_feat_label_convert = df_test_Byte_TFIDF_feat.replace({'label' : labels_to_integers})\n",
    "    df_test_Byte_TFIDF_feat_no_label = df_test_Byte_TFIDF_feat_label_convert.drop('label', axis=1)\n",
    "    inputs_test = df_test_Byte_TFIDF_feat_no_label.to_numpy()\n",
    "    outputs_string_test = df_test_Byte_TFIDF_feat['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set random seed\n",
    "np.random.seed(30)\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert inputs to float32 type\n",
    "X_train = inputs.astype('float32')\n",
    "X_test = inputs_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change this logic for multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert labels to integers\n",
    "mapping = labels_to_integers\n",
    "\n",
    "Y_train1 = outputs_string\n",
    "Y_test1 = outputs_string_test\n",
    "# Replace values using numpy.where()\n",
    "for integer in labels_to_integers.keys():\n",
    "    Y_train1 = np.where(Y_train1 == integer, mapping[integer], Y_train1)\n",
    "    Y_test1 = np.where(Y_test1 == integer, mapping[integer], Y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert labels to categorical\n",
    "num_labels=len(labels_to_integers.keys())\n",
    "Y_train = tf.keras.utils.to_categorical(Y_train1, num_classes=num_labels)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test1, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomize order of inputs\n",
    "num_inputs = len(X_train)\n",
    "randomize = np.arange(num_inputs)\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "X_train = X_train[randomize]\n",
    "Y_train = Y_train[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               35072     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 43,523\n",
      "Trainable params: 43,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 14:11:56.249845: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-21 14:11:56.250532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-08-21 14:11:56.281780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-21 14:11:56.282236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:68:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-21 14:11:56.282276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-08-21 14:11:56.288121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-08-21 14:11:56.288200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-08-21 14:11:56.314358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-08-21 14:11:56.314592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-08-21 14:11:56.315755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-08-21 14:11:56.316368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-08-21 14:11:56.316549: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-08-21 14:11:56.316557: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-21 14:11:56.316833: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 14:11:56.317609: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-21 14:11:56.317630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-08-21 14:11:56.317634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n"
     ]
    }
   ],
   "source": [
    "#Set dropout rate \n",
    "dropout_rate = 0.15\n",
    "model_path = \"models\"\n",
    "\n",
    "#Add model architecture\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(keras.layers.Dropout(dropout_rate))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(len(labels_to_integers.keys()), activation='softmax'))\n",
    "\n",
    "#Check model architecture\n",
    "print(model.summary())\n",
    "\n",
    "#Add Adam optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001,\n",
    "                            beta_1=0.9,\n",
    "                            beta_2=0.999,\n",
    "                            epsilon=1e-07)\n",
    "#Compile model with Categorical Crossentropy loss function and for classification accuracy\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import for Keras callback\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def callbacks(PATH_BEST_MODEL, monitor, verbose, mode, save_best_only):  \n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\n",
    "        os.path.join(PATH_BEST_MODEL, 'dnn.hdf5'), \n",
    "        monitor=monitor, \n",
    "        verbose=verbose, \n",
    "        mode=mode, \n",
    "        save_best_only=save_best_only\n",
    "    )\n",
    "\n",
    "    return [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 14:11:56.450520: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-08-21 14:11:56.467688: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3699850000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "171/171 [==============================] - 1s 7ms/step - loss: 0.7614 - accuracy: 0.6842 - val_loss: 0.3879 - val_accuracy: 0.8459\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.84589, saving model to models/dnn.hdf5\n",
      "Epoch 2/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.3721 - accuracy: 0.8555 - val_loss: 0.2883 - val_accuracy: 0.8962\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.84589 to 0.89619, saving model to models/dnn.hdf5\n",
      "Epoch 3/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.2827 - accuracy: 0.8971 - val_loss: 0.2368 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.89619 to 0.91978, saving model to models/dnn.hdf5\n",
      "Epoch 4/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.2335 - accuracy: 0.9207 - val_loss: 0.2033 - val_accuracy: 0.9350\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91978 to 0.93504, saving model to models/dnn.hdf5\n",
      "Epoch 5/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.1991 - accuracy: 0.9332 - val_loss: 0.1818 - val_accuracy: 0.9432\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.93504 to 0.94324, saving model to models/dnn.hdf5\n",
      "Epoch 6/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.1769 - accuracy: 0.9436 - val_loss: 0.1703 - val_accuracy: 0.9462\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.94324 to 0.94617, saving model to models/dnn.hdf5\n",
      "Epoch 7/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.1621 - accuracy: 0.9482 - val_loss: 0.1578 - val_accuracy: 0.9522\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.94617 to 0.95222, saving model to models/dnn.hdf5\n",
      "Epoch 8/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.1466 - accuracy: 0.9543 - val_loss: 0.1525 - val_accuracy: 0.9532\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.95222 to 0.95323, saving model to models/dnn.hdf5\n",
      "Epoch 9/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.1358 - accuracy: 0.9585 - val_loss: 0.1460 - val_accuracy: 0.9544\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.95323 to 0.95442, saving model to models/dnn.hdf5\n",
      "Epoch 10/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.1284 - accuracy: 0.9607 - val_loss: 0.1455 - val_accuracy: 0.9554\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.95442 to 0.95542, saving model to models/dnn.hdf5\n",
      "Epoch 11/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.1191 - accuracy: 0.9637 - val_loss: 0.1411 - val_accuracy: 0.9576\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.95542 to 0.95758, saving model to models/dnn.hdf5\n",
      "Epoch 12/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.1145 - accuracy: 0.9664 - val_loss: 0.1359 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.95758 to 0.95900, saving model to models/dnn.hdf5\n",
      "Epoch 13/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.1071 - accuracy: 0.9677 - val_loss: 0.1349 - val_accuracy: 0.9590\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.95900 to 0.95904, saving model to models/dnn.hdf5\n",
      "Epoch 14/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.1040 - accuracy: 0.9697 - val_loss: 0.1351 - val_accuracy: 0.9593\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.95904 to 0.95927, saving model to models/dnn.hdf5\n",
      "Epoch 15/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0980 - accuracy: 0.9706 - val_loss: 0.1345 - val_accuracy: 0.9604\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.95927 to 0.96042, saving model to models/dnn.hdf5\n",
      "Epoch 16/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0971 - accuracy: 0.9719 - val_loss: 0.1364 - val_accuracy: 0.9594\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.96042\n",
      "Epoch 17/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0908 - accuracy: 0.9753 - val_loss: 0.1323 - val_accuracy: 0.9609\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.96042 to 0.96092, saving model to models/dnn.hdf5\n",
      "Epoch 18/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0904 - accuracy: 0.9738 - val_loss: 0.1332 - val_accuracy: 0.9608\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.96092\n",
      "Epoch 19/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0856 - accuracy: 0.9745 - val_loss: 0.1323 - val_accuracy: 0.9620\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.96092 to 0.96202, saving model to models/dnn.hdf5\n",
      "Epoch 20/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0821 - accuracy: 0.9761 - val_loss: 0.1318 - val_accuracy: 0.9613\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.96202\n",
      "Epoch 21/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0798 - accuracy: 0.9771 - val_loss: 0.1308 - val_accuracy: 0.9620\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.96202\n",
      "Epoch 22/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0773 - accuracy: 0.9781 - val_loss: 0.1341 - val_accuracy: 0.9616\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.96202\n",
      "Epoch 23/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0755 - accuracy: 0.9782 - val_loss: 0.1349 - val_accuracy: 0.9621\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.96202 to 0.96211, saving model to models/dnn.hdf5\n",
      "Epoch 24/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0727 - accuracy: 0.9794 - val_loss: 0.1335 - val_accuracy: 0.9620\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.96211\n",
      "Epoch 25/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0722 - accuracy: 0.9785 - val_loss: 0.1354 - val_accuracy: 0.9618\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.96211\n",
      "Epoch 26/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0685 - accuracy: 0.9805 - val_loss: 0.1362 - val_accuracy: 0.9618\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.96211\n",
      "Epoch 27/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0667 - accuracy: 0.9803 - val_loss: 0.1365 - val_accuracy: 0.9621\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.96211\n",
      "Epoch 28/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0637 - accuracy: 0.9813 - val_loss: 0.1381 - val_accuracy: 0.9621\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.96211\n",
      "Epoch 29/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0616 - accuracy: 0.9818 - val_loss: 0.1391 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.96211\n",
      "Epoch 30/30\n",
      "171/171 [==============================] - 1s 5ms/step - loss: 0.0605 - accuracy: 0.9814 - val_loss: 0.1426 - val_accuracy: 0.9622\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.96211 to 0.96216, saving model to models/dnn.hdf5\n"
     ]
    }
   ],
   "source": [
    "#Run model with hyperparameters\n",
    "history = model.fit(X_train, Y_train, epochs=30, initial_epoch=0, verbose=1, batch_size=512, validation_split=0.2, use_multiprocessing=True,\n",
    "                    callbacks=callbacks(      \n",
    "                PATH_BEST_MODEL=model_path,\n",
    "                monitor=\"val_accuracy\",\n",
    "                verbose=1, \n",
    "                mode=\"max\", \n",
    "                save_best_only=True\n",
    "            ),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the best model\n",
    "model_path_full = 'models/dnn.hdf5'\n",
    "model = tf.keras.models.load_model(model_path_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the Accuracy and Loss curves\n",
    "from matplotlib import pyplot as plt\n",
    "fig, axes = plt.subplots(1, 1, figsize=(6, 6))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Accuracy and Loss Curves', fontweight='bold', fontsize=18)\n",
    "# plt.ylabel('Accuracy & Loss', fontweight='bold', fontsize=13)\n",
    "plt.xlabel('Number of Epochs', fontweight='bold', fontsize=14)\n",
    "plt.legend(['Train F1-score', 'Validation F1-score', 'Train Loss', 'Validation Loss'], loc='right', fontsize=12)\n",
    "plt.show()\n",
    "fig.savefig('results/Model_F1-Score_and_Loss_Curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set performance\n",
      "853/853 [==============================] - 1s 1ms/step - loss: 0.1381 - accuracy: 0.9625\n"
     ]
    }
   ],
   "source": [
    "print('Test set performance')\n",
    "test_perf = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      9095\n",
      "           1       0.96      0.97      0.97      9095\n",
      "           2       0.96      0.98      0.97      9095\n",
      "\n",
      "    accuracy                           0.96     27285\n",
      "   macro avg       0.96      0.96      0.96     27285\n",
      "weighted avg       0.96      0.96      0.96     27285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate and create a Classification Report and save it\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming 'model' is your trained Keras model and 'x_test', 'y_test' are your test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=-1)\n",
    "y_true_classes = Y_test.argmax(axis=-1)\n",
    "\n",
    "#Create Classification Report\n",
    "print(classification_report(y_true_classes, y_pred_classes))\n",
    "report = classification_report(y_true_classes, y_pred_classes, output_dict=True)\n",
    "\n",
    "#Save it in csv\n",
    "df_dnn = pd.DataFrame(report).transpose()\n",
    "if input_type == \"Byte\":\n",
    "    df_dnn.to_csv('results/DNN Report Byte.csv')\n",
    "else:\n",
    "    df_dnn.to_csv('results/DNN Report Char.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13808844983577728, 0.9624702334403992]\n"
     ]
    }
   ],
   "source": [
    "print(test_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 14:12:27.477560: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp9sd4ipss/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 14:12:27.740177: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2\n",
      "2023-08-21 14:12:27.740247: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2023-08-21 14:12:27.740533: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-21 14:12:27.880670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-21 14:12:27.880849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:68:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-21 14:12:27.880877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-08-21 14:12:27.880897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-08-21 14:12:27.880905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-08-21 14:12:27.880912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-08-21 14:12:27.880920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-08-21 14:12:27.880927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-08-21 14:12:27.880934: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-08-21 14:12:27.880990: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-08-21 14:12:27.880995: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-21 14:12:27.881008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-08-21 14:12:27.881013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2023-08-21 14:12:27.881018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N \n",
      "2023-08-21 14:12:27.881020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N \n",
      "2023-08-21 14:12:27.883227: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.003ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2023-08-21 14:12:27.918941: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.\n",
      "2023-08-21 14:12:27.918968: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.\n",
      "2023-08-21 14:12:27.922027: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-21 14:12:27.922363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-21 14:12:27.922534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:68:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-21 14:12:27.922566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-08-21 14:12:27.922593: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-08-21 14:12:27.922603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-08-21 14:12:27.922612: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-08-21 14:12:27.922622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-08-21 14:12:27.922631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-08-21 14:12:27.922639: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-08-21 14:12:27.922702: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-08-21 14:12:27.922707: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-21 14:12:27.922723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-08-21 14:12:27.922726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2023-08-21 14:12:27.922730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N \n",
      "2023-08-21 14:12:27.922733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N \n"
     ]
    }
   ],
   "source": [
    "# Passing the Keras model to the TF Lite Converter.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Using float-16 quantization.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float32]\n",
    "\n",
    "# Converting the model.\n",
    "tflite_fp16_model = converter.convert()\n",
    " \n",
    "# Saving the model.\n",
    "with open('models/fp_16_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_fp16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdgmvecoq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdgmvecoq/assets\n",
      "2023-08-21 14:12:28.260893: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2\n",
      "2023-08-21 14:12:28.261010: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2023-08-21 14:12:28.261280: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-21 14:12:28.261516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-21 14:12:28.261676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:68:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-21 14:12:28.261702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-08-21 14:12:28.261721: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-08-21 14:12:28.261729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-08-21 14:12:28.261737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-08-21 14:12:28.261744: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-08-21 14:12:28.261753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-08-21 14:12:28.261760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-08-21 14:12:28.261817: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-08-21 14:12:28.261821: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-21 14:12:28.261839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-08-21 14:12:28.261842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2023-08-21 14:12:28.261846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N \n",
      "2023-08-21 14:12:28.261849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N \n",
      "2023-08-21 14:12:28.262831: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2023-08-21 14:12:28.297796: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.\n",
      "2023-08-21 14:12:28.297822: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.\n",
      "2023-08-21 14:12:28.306059: I tensorflow/lite/tools/optimize/quantize_weights.cc:222] Skipping quantization of tensor sequential/dense_2/MatMul because it has fewer than 1024 elements (192).\n"
     ]
    }
   ],
   "source": [
    "# Passing the baseline Keras model to the TF Lite Converter.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Using  the Dynamic Range Quantization.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Converting the model\n",
    "tflite_quant_model = converter.convert()\n",
    "# Saving the model.\n",
    "with open('models/dynamic_quant_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphkxtrf48/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphkxtrf48/assets\n",
      "2023-08-21 14:12:28.640252: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2\n",
      "2023-08-21 14:12:28.640321: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2023-08-21 14:12:28.640544: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-21 14:12:28.640769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-21 14:12:28.640926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:68:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-21 14:12:28.640953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-08-21 14:12:28.640972: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2023-08-21 14:12:28.640980: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-08-21 14:12:28.640988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-08-21 14:12:28.640995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-08-21 14:12:28.641003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-08-21 14:12:28.641010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-08-21 14:12:28.641073: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-08-21 14:12:28.641078: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-08-21 14:12:28.641095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-08-21 14:12:28.641099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2023-08-21 14:12:28.641102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N \n",
      "2023-08-21 14:12:28.641105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N \n",
      "2023-08-21 14:12:28.641793: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n",
      "2023-08-21 14:12:28.659112: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.\n",
      "2023-08-21 14:12:28.659132: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "# Passing the baseline Keras model to the TF Lite Converter.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Defining the representative dataset from training images.\n",
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(X_train).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Using Integer Quantization.\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    " \n",
    "# Setting the input and output tensors to uint8.\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "# Converting the model.\n",
    "int_quant_model = converter.convert()\n",
    " \n",
    "# Saving the Integer Quantized TF Lite model.\n",
    "with open('models/int_quant_model.tflite', 'wb') as f:\n",
    "    f.write(int_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for evaluating TF Lite Model over Test Images\n",
    "def evaluate(interpreter):\n",
    "    prediction= []\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "    input_format = interpreter.get_output_details()[0]['dtype']\n",
    "    \n",
    "    for i, test_image in enumerate(X_test):\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(input_format)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.tensor(output_index)\n",
    "        predicted_label = np.argmax(output()[0])\n",
    "        prediction.append(predicted_label)\n",
    "\n",
    "    print('\\n')\n",
    "    # Comparing prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction = np.array(prediction)\n",
    "\n",
    "    accuracy = (prediction == Y_test1).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Float 16 Quantized TFLite Model Test Accuracy: 96.24702217335532\n"
     ]
    }
   ],
   "source": [
    "# Passing the FP-16 TF Lite model to the interpreter.\n",
    "interpreter = tf.lite.Interpreter('models/fp_16_model.tflite')\n",
    "# Allocating tensors.\n",
    "interpreter.allocate_tensors()\n",
    "# Evaluating the model on the test dataset.\n",
    "test_accuracy = evaluate(interpreter)\n",
    "print('Float 16 Quantized TFLite Model Test Accuracy:', test_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dynamically Quantized TFLite Model Test Accuracy: 96.27634231262599\n"
     ]
    }
   ],
   "source": [
    "# Passing the Dynamic Range Quantized TF Lite model to the Interpreter.\n",
    "interpreter = tf.lite.Interpreter('models/dynamic_quant_model.tflite') \n",
    "# Allocating tensors.\n",
    "interpreter.allocate_tensors()\n",
    "# Evaluating the model on the test images.\n",
    "test_accuracy = evaluate(interpreter)\n",
    "print('Dynamically Quantized TFLite Model Test Accuracy:', test_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Integer Quantized TFLite Model Test Accuracy: 33.33333333333333\n"
     ]
    }
   ],
   "source": [
    "# Passing the Integer Quantized TF Lite model to the Interpreter.\n",
    "interpreter = tf.lite.Interpreter('models/int_quant_model.tflite')\n",
    "# Allocating tensors.\n",
    "interpreter.allocate_tensors()\n",
    "# Evaluating the model on the test images.\n",
    "test_accuracy = evaluate(interpreter)\n",
    "print('Integer Quantized TFLite Model Test Accuracy:', test_accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_model(model, name, feat_test, y_test, input_type=\"Byte\"):\n",
    "    \"\"\" Evaluate a classification model on the test set, then print and plot metrics. \"\"\"\n",
    "    # Make prediction from features\n",
    "    pred_test = model.predict(feat_test)\n",
    "    \n",
    "    print(f\"\\n[ Evaluation result for {name} ]\")\n",
    "    # Print classification report\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, pred_test))\n",
    "    report = classification_report(y_test, pred_test, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    # Save classification report as CSV\n",
    "    df.to_csv('results/{} Report {}.csv'.format(name,input_type))\n",
    "\n",
    "## Converting labels  to integer values\n",
    "def label_to_numeric(row):\n",
    "    \"\"\"Convert label to integers\"\"\"\n",
    "    distinct_labels = labels_to_integers.keys()\n",
    "    index_ = distinct_labels.index(row[\"label\"])\n",
    "    return index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_ML_models(df_train, df_test, input_type=\"Byte\"):\n",
    "    ## Visualize the dataset in tabular format\n",
    "    print('Total Number of Training data samples:', df_train.shape[0])\n",
    "    print('Total Number of Testing data samples:', df_test.shape[0])\n",
    "    print('Number of features per data sample:', df_train.shape[1]-1)\n",
    "    print('Distinct labels (Architecture Types):\\n',label_counter.keys())\n",
    "    \n",
    "    df_train_tmp = copy.deepcopy(df_train)\n",
    "    df_test_tmp = copy.deepcopy(df_test)\n",
    "    \n",
    "    df_train_tmp[\"label\"] = df_train_tmp['label'].replace(labels_to_integers)\n",
    "    df_test_tmp[\"label\"] = df_test_tmp['label'].replace(labels_to_integers)\n",
    "\n",
    "    #Train and Test labels\n",
    "    y_train = df_train_tmp.pop(\"label\").values\n",
    "    y_test = df_test_tmp.pop(\"label\").values\n",
    "    \n",
    "    #Train and Test data\n",
    "    X_train = df_train_tmp.values\n",
    "    X_test = df_test_tmp.values\n",
    "\n",
    "    #SVM\n",
    "    SVC_model = LinearSVC(random_state=123, max_iter=200)\n",
    "    SVC_model.fit(X_train, y_train)\n",
    "    classification_report = evaluate_model(SVC_model, \"Support Vector Machine Classifier\", X_test, y_test, input_type) \n",
    "    SVC_acc = np.round(SVC_model.score(X_test, y_test)*100,4)\n",
    "    print(SVC_acc)\n",
    "\n",
    "    #LR\n",
    "    LR_model = LogisticRegression(random_state=123, max_iter =200)\n",
    "    LR_model.fit(X_train, y_train)\n",
    "    evaluate_model(LR_model, \"Logistic Regression Classifier\", X_test, y_test, input_type) \n",
    "    LR_acc = np.round(LR_model.score(X_test, y_test)*100,4)\n",
    "    print(LR_acc)\n",
    "    \n",
    "    #GNB\n",
    "    GNB_model = GaussianNB()\n",
    "    GNB_model.fit(X_train, y_train)\n",
    "    evaluate_model(GNB_model, \"Gaussian Naive Bayes Classifier\", X_test, y_test, input_type) \n",
    "    GNB_acc = np.round(GNB_model.score(X_test, y_test)*100,4)\n",
    "    print(GNB_acc)\n",
    "\n",
    "    #DT\n",
    "    DT_model = DecisionTreeClassifier(random_state=1234567)\n",
    "    DT_model.fit(X_train, y_train)\n",
    "    evaluate_model(DT_model, \"Decision Tree Classifier\", X_test, y_test, input_type) \n",
    "    DT_acc = np.round(DT_model.score(X_test, y_test)*100,4)\n",
    "    print(DT_acc)\n",
    "\n",
    "#     RF\n",
    "    RF_model = RandomForestClassifier(random_state=1234567)\n",
    "    RF_model.fit(X_train, y_train)\n",
    "    evaluate_model(RF_model, \"Random Forest Classifier\", X_test, y_test, input_type) \n",
    "    RF_acc = np.round(RF_model.score(X_test, y_test)*100,4)\n",
    "    print(RF_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Byte Level TF-IDF - Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_type == \"Byte\" or input_type == \"All\":\n",
    "    train_test_ML_models(df_train_Byte_TFIDF_feat, df_test_Byte_TFIDF_feat, input_type=\"Byte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Char Level TF-IDF - Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Training data samples: 109137\n",
      "Total Number of Testing data samples: 27285\n",
      "Number of features per data sample: 273\n",
      "Distinct labels (Architecture Types):\n",
      " dict_keys(['Spoofing', 'Normal', 'Fuzzing'])\n",
      "\n",
      "[ Evaluation result for Support Vector Machine Classifier ]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      9095\n",
      "           1       0.77      0.73      0.75      9095\n",
      "           2       0.94      0.97      0.95      9095\n",
      "\n",
      "    accuracy                           0.82     27285\n",
      "   macro avg       0.81      0.82      0.81     27285\n",
      "weighted avg       0.81      0.82      0.81     27285\n",
      "\n",
      "81.5027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsl/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Evaluation result for Logistic Regression Classifier ]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74      9095\n",
      "           1       0.77      0.73      0.75      9095\n",
      "           2       0.94      0.97      0.96      9095\n",
      "\n",
      "    accuracy                           0.82     27285\n",
      "   macro avg       0.81      0.82      0.81     27285\n",
      "weighted avg       0.81      0.82      0.81     27285\n",
      "\n",
      "81.5466\n",
      "\n",
      "[ Evaluation result for Gaussian Naive Bayes Classifier ]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65      9095\n",
      "           1       0.65      0.68      0.66      9095\n",
      "           2       0.92      0.89      0.90      9095\n",
      "\n",
      "    accuracy                           0.74     27285\n",
      "   macro avg       0.74      0.74      0.74     27285\n",
      "weighted avg       0.74      0.74      0.74     27285\n",
      "\n",
      "73.6522\n",
      "\n",
      "[ Evaluation result for Decision Tree Classifier ]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      9095\n",
      "           1       0.98      0.98      0.98      9095\n",
      "           2       0.96      0.96      0.96      9095\n",
      "\n",
      "    accuracy                           0.97     27285\n",
      "   macro avg       0.97      0.97      0.97     27285\n",
      "weighted avg       0.97      0.97      0.97     27285\n",
      "\n",
      "96.7565\n",
      "\n",
      "[ Evaluation result for Random Forest Classifier ]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      9095\n",
      "           1       0.97      0.98      0.98      9095\n",
      "           2       0.96      0.98      0.97      9095\n",
      "\n",
      "    accuracy                           0.97     27285\n",
      "   macro avg       0.97      0.97      0.97     27285\n",
      "weighted avg       0.97      0.97      0.97     27285\n",
      "\n",
      "96.9324\n"
     ]
    }
   ],
   "source": [
    "if input_type == \"Char\" or input_type == \"All\":\n",
    "    train_test_ML_models(df_train_Char_TFIDF_feat, df_test_Char_TFIDF_feat, input_type=\"Char\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:CAN38]",
   "language": "python",
   "name": "conda-env-CAN38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
